[
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching Experience",
    "section": "",
    "text": "Teaching Assistant, Machine Learning\nHelping the professor in course logistics, creating assignments and evaluation.\nTeaching Assistant, Probability and Random Processes\nConducted discussion sessions and drafted tutorial solutions. Created and evaluated assignments based on Computer Vision and Image Processing.\nPeer Assisted Learning Mentor\nMentored freshmen students, and coached them in English to help them ease into campus life.\nCertification in Teaching\nCompleted 6-week long program engaging in practice modules and seminars aimed at developing and enhancing teaching skills."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Deep Gaussian Processes for Air Quality Inference\nEshan Gujarathi, Aadesh Desai, Saagar Parikh, Sachin Yadav, Zeel Patel, Nipun Batra. Accepted in ACM India 6th Joint International Conference on Data Science & Management of Data (10th ACM IKDD CODS and 28th COMAD) (CODS-COMAD 2023)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Eshan Gujarathi",
    "section": "",
    "text": "I am a Post Baccalaureate Fellow at the Robert Bosch Center for Data Science and Artificial Intelligence at IIT Madras, working under the guidance of Prof.Â Balaraman Ravindran. I recently completed my B.Tech with Honours in Computer Science and Engineering from IIT Gandhinagar. I am a creative, diligent, and result-oriented individual who always looks for new opportunities to grow.\nMy research interests include Applied Machine Learning, Computer Vision, Bayesian Learning, and Data Science. I am passionate about applying Artificial Intelligence to critical applications with a broader impact.\n \n  \n   \n  \n    \n     Twitter\n  \n  \n    \n     Github\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     Email\n  \n  \n    \n     Google Scholar"
  },
  {
    "objectID": "blogs/fcnn_on_mnist.html",
    "href": "blogs/fcnn_on_mnist.html",
    "title": "FCNN on MNIST",
    "section": "",
    "text": "import keras\n# from data_handlers import *\nimport pandas as pd\nimport numpy as np\n\n\nfrom keras.datasets import mnist\n(x_train,y_train),(x_test,y_test)=mnist.load_data()\n\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11493376/11490434 [==============================] - 0s 0us/step\n11501568/11490434 [==============================] - 0s 0us/step\n\n\n\nx_train = x_train.reshape(60000,784)\nx_test = x_test.reshape(10000,784)\nx_train = x_train/255.0\nx_test = x_test/255.0\ny_train = np.reshape(y_train, (len(y_train), 1))\n\n\nfrom keras.layers import Dense\nfrom keras.models import Sequential\n\n\nimport tensorflow as tf\n\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\nX_train.shape,y_train.shape, X_val.shape,y_val.shape\n\n((48000, 784), (48000, 1), (12000, 784), (12000, 1))\n\n\n\ntf.random.set_seed(42)\n\nmodel = tf.keras.Sequential([\n    \n    tf.keras.layers.Dense(1000, activation=\"relu\"),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(784, activation=\"relu\"),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(400, activation=\"relu\"),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(200, activation=\"relu\"),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(10, activation=\"softmax\")\n    \n])\n\nmodel.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                 optimizer=tf.keras.optimizers.Adam(lr=0.001), # ideal learning rate (same as default)\n                 metrics=[\"accuracy\"])\n\n\n/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n  super(Adam, self).__init__(name, **kwargs)\n\n\n\nhistory = model.fit(\n    X_train,\n    y_train,\n    epochs=30,\n    validation_data=(X_val, y_val)\n)\n\nEpoch 1/30\n1500/1500 [==============================] - 37s 24ms/step - loss: 0.2767 - accuracy: 0.9181 - val_loss: 0.1590 - val_accuracy: 0.9528\nEpoch 2/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.1453 - accuracy: 0.9603 - val_loss: 0.1049 - val_accuracy: 0.9718\nEpoch 3/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.1137 - accuracy: 0.9686 - val_loss: 0.1158 - val_accuracy: 0.9688\nEpoch 4/30\n1500/1500 [==============================] - 39s 26ms/step - loss: 0.0944 - accuracy: 0.9739 - val_loss: 0.1138 - val_accuracy: 0.9724\nEpoch 5/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.0870 - accuracy: 0.9761 - val_loss: 0.1001 - val_accuracy: 0.9750\nEpoch 6/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.0749 - accuracy: 0.9794 - val_loss: 0.1040 - val_accuracy: 0.9754\nEpoch 7/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.0701 - accuracy: 0.9808 - val_loss: 0.1053 - val_accuracy: 0.9775\nEpoch 8/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.0711 - accuracy: 0.9820 - val_loss: 0.0934 - val_accuracy: 0.9793\nEpoch 9/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.0620 - accuracy: 0.9836 - val_loss: 0.0944 - val_accuracy: 0.9774\nEpoch 10/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.0545 - accuracy: 0.9859 - val_loss: 0.0992 - val_accuracy: 0.9783\nEpoch 11/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.0551 - accuracy: 0.9857 - val_loss: 0.1464 - val_accuracy: 0.9728\nEpoch 12/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.0581 - accuracy: 0.9861 - val_loss: 0.1384 - val_accuracy: 0.9731\nEpoch 13/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.0475 - accuracy: 0.9876 - val_loss: 0.1219 - val_accuracy: 0.9775\nEpoch 14/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.0544 - accuracy: 0.9872 - val_loss: 0.1042 - val_accuracy: 0.9812\nEpoch 15/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.0428 - accuracy: 0.9895 - val_loss: 0.1182 - val_accuracy: 0.9807\nEpoch 16/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.0459 - accuracy: 0.9894 - val_loss: 0.1164 - val_accuracy: 0.9797\nEpoch 17/30\n1500/1500 [==============================] - 37s 25ms/step - loss: 0.0420 - accuracy: 0.9903 - val_loss: 0.1044 - val_accuracy: 0.9834\nEpoch 18/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.0441 - accuracy: 0.9892 - val_loss: 0.1372 - val_accuracy: 0.9789\nEpoch 19/30\n1500/1500 [==============================] - 35s 24ms/step - loss: 0.0395 - accuracy: 0.9912 - val_loss: 0.1800 - val_accuracy: 0.9767\nEpoch 20/30\n1500/1500 [==============================] - 35s 24ms/step - loss: 0.0459 - accuracy: 0.9898 - val_loss: 0.1399 - val_accuracy: 0.9787\nEpoch 21/30\n1500/1500 [==============================] - 35s 24ms/step - loss: 0.0462 - accuracy: 0.9892 - val_loss: 0.1615 - val_accuracy: 0.9780\nEpoch 22/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.0342 - accuracy: 0.9911 - val_loss: 0.1540 - val_accuracy: 0.9819\nEpoch 23/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.0406 - accuracy: 0.9913 - val_loss: 0.1259 - val_accuracy: 0.9839\nEpoch 24/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.0387 - accuracy: 0.9917 - val_loss: 0.1566 - val_accuracy: 0.9787\nEpoch 25/30\n1500/1500 [==============================] - 39s 26ms/step - loss: 0.0441 - accuracy: 0.9912 - val_loss: 0.1574 - val_accuracy: 0.9807\nEpoch 26/30\n1500/1500 [==============================] - 37s 24ms/step - loss: 0.0391 - accuracy: 0.9913 - val_loss: 0.1485 - val_accuracy: 0.9829\nEpoch 27/30\n1500/1500 [==============================] - 37s 24ms/step - loss: 0.0414 - accuracy: 0.9914 - val_loss: 0.1894 - val_accuracy: 0.9783\nEpoch 28/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.0389 - accuracy: 0.9922 - val_loss: 0.1380 - val_accuracy: 0.9812\nEpoch 29/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.0412 - accuracy: 0.9916 - val_loss: 0.1605 - val_accuracy: 0.9812\nEpoch 30/30\n1500/1500 [==============================] - 36s 24ms/step - loss: 0.0398 - accuracy: 0.9918 - val_loss: 0.1563 - val_accuracy: 0.9832\n\n\n\npredictions = model.predict(x_test)\ny_preds = predictions.argmax(axis =1)\n\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_preds))\n\n              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99       980\n           1       0.99      0.99      0.99      1135\n           2       0.99      0.98      0.98      1032\n           3       0.98      0.98      0.98      1010\n           4       0.97      0.98      0.98       982\n           5       0.97      0.99      0.98       892\n           6       0.99      0.98      0.98       958\n           7       0.99      0.96      0.98      1028\n           8       0.97      0.97      0.97       974\n           9       0.97      0.98      0.98      1009\n\n    accuracy                           0.98     10000\n   macro avg       0.98      0.98      0.98     10000\nweighted avg       0.98      0.98      0.98     10000\n\n\n\n\ndef accuracy(y_hat, y):\n    \n    assert(y_hat.size == y.size)\n    count=0\n    for i in range(y.size):\n        if (y[i]==y_hat[i]):\n            count = count + 1\n    acc = count/y.size\n    return acc\n    pass\n\nprint(accuracy(y_preds,y_test))\n\n0.9816\n\n\n\nimport itertools\nfrom sklearn.metrics import confusion_matrix\n\n\n# Our function needs a different name to sklearn's plot_confusion_matrix\ndef make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15): \n  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n\n  If classes is passed, confusion matrix will be labelled, if not, integer class values\n  will be used.\n\n  Args:\n    y_true: Array of truth labels (must be same shape as y_pred).\n    y_pred: Array of predicted labels (must be same shape as y_true).\n    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n    figsize: Size of output figure (default=(10, 10)).\n    text_size: Size of output figure text (default=15).\n  \n  Returns:\n    A labelled confusion matrix plot comparing y_true and y_pred.\n\n  Example usage:\n    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n                          y_pred=y_preds, # predicted labels\n                          classes=class_names, # array of class label names\n                          figsize=(15, 15),\n                          text_size=10)\n  \"\"\"  \n  # Create the confustion matrix\n  cm = confusion_matrix(y_true, y_pred)\n  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n  n_classes = cm.shape[0] # find the number of classes we're dealing with\n\n  # Plot the figure and make it pretty\n  fig, ax = plt.subplots(figsize=figsize)\n  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n  fig.colorbar(cax)\n\n  # Are there a list of classes?\n  if classes:\n    labels = classes\n  else:\n    labels = np.arange(cm.shape[0])\n  \n  # Label the axes\n  ax.set(title=\"Confusion Matrix\",\n         xlabel=\"Predicted label\",\n         ylabel=\"True label\",\n         xticks=np.arange(n_classes), # create enough axis slots for each class\n         yticks=np.arange(n_classes), \n         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n         yticklabels=labels)\n  \n  # Make x-axis labels appear on bottom\n  ax.xaxis.set_label_position(\"bottom\")\n  ax.xaxis.tick_bottom()\n\n  # Set the threshold for different colors\n  threshold = (cm.max() + cm.min()) / 2.\n\n  # Plot the text on each cell\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n             horizontalalignment=\"center\",\n             color=\"white\" if cm[i, j] &gt; threshold else \"black\",\n             size=text_size)\n\n\nimport matplotlib.pyplot as plt\n\n\nclass_names = ['0', '1', '2', '3', '4', \n               '5', '6', '7', '8', '9']\n\n\nmake_confusion_matrix(y_true=y_test, \n                      y_pred=y_preds,\n                      classes=class_names,\n                      figsize=(15, 15),\n                      text_size=10)\n\n\n\n\n\nmodel.summary()\n\nModel: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 1000)              785000    \n                                                                 \n dropout (Dropout)           (None, 1000)              0         \n                                                                 \n dense_1 (Dense)             (None, 784)               784784    \n                                                                 \n dropout_1 (Dropout)         (None, 784)               0         \n                                                                 \n dense_2 (Dense)             (None, 400)               314000    \n                                                                 \n dropout_2 (Dropout)         (None, 400)               0         \n                                                                 \n dense_3 (Dense)             (None, 200)               80200     \n                                                                 \n dropout_3 (Dropout)         (None, 200)               0         \n                                                                 \n dense_4 (Dense)             (None, 10)                2010      \n                                                                 \n=================================================================\nTotal params: 1,965,994\nTrainable params: 1,965,994\nNon-trainable params: 0\n_________________________________________________________________\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\n\nfrom sklearn import svm, datasets\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import roc_auc_score\n\ny_test1 = label_binarize(y_test, classes=[0,1,2,3,4,5,6,7,8,9])\ny_preds1 = label_binarize(y_preds, classes=[0,1,2,3,4,5,6,7,8,9])\n\n\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(10):\n    fpr[i], tpr[i], _ = roc_curve(y_test1[:, i], y_preds1[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test1.ravel(), y_preds1.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n\nall_fpr = np.unique(np.concatenate([fpr[i] for i in range(10)]))\nlw=2\n# Then interpolate all ROC curves at this points\nmean_tpr = np.zeros_like(all_fpr)\nfor i in range(10):\n    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n\n# Finally average it and compute AUC\nmean_tpr /= 10\n\nfpr[\"macro\"] = all_fpr\ntpr[\"macro\"] = mean_tpr\nroc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n# Plot all ROC curves\nplt.figure()\nplt.plot(\n    fpr[\"micro\"],\n    tpr[\"micro\"],\n    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n    color=\"deeppink\",\n    linestyle=\":\",\n    linewidth=4,\n)\n\nplt.plot(\n    fpr[\"macro\"],\n    tpr[\"macro\"],\n    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n    color=\"navy\",\n    linestyle=\":\",\n    linewidth=4,\n)\n\ncolors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\nfor i, color in zip(range(10), colors):\n    plt.plot(\n        fpr[i],\n        tpr[i],\n        color=color,\n        lw=lw,\n        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(i, roc_auc[i]),\n    )\n\nplt.plot([0, 1], [0, 1], \"k--\", lw=lw)\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.title(\"FCN\")\nplt.legend(loc=\"lower right\")\nplt.show()"
  },
  {
    "objectID": "achievements.html",
    "href": "achievements.html",
    "title": "Achievements",
    "section": "",
    "text": "Selected to attend Research Week with Google, a graduate research symposium on Machine Learning research. (2023)\nAwarded the Summer Undergraduate Research Fellowship (SURF) to conduct research at the California Institute of Technology for a period of 10 weeks. (2022)\nSelected for research internship at the University of Alberta, Edmonton through the Mitacs GRI Program. (2022)\nRecipient of the Neha and Vinay Gupta Scholarship at IITGN for excellent performance in A.Y. 2021-22. (INR 100k) (2022)\nHonoured with the Deanâs List Award for academic excellence in 4 out of 5 eligible semesters. (2020 - 2022)\nSecured First Position in the 3-day Kaggle ML Challenge at Hackrush â21, IITGN. (2021)"
  },
  {
    "objectID": "blogs/pandas_revision.html",
    "href": "blogs/pandas_revision.html",
    "title": "Pandas Cheat Sheet",
    "section": "",
    "text": "Pandas cheat sheet\nIn this blog, I go through some of the basics of pandas\n\nImporting and using some basic functions of pandas\n\n#imports\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n\n#reading an already existing csv file in a dataframe\nraw = pd.read_csv(\"https://pythonandvba.com/youtube-data.csv\")\n\n\n#printing the first 5 rows\nraw.head(5)\n\n\n  \n    \n      \n\n\n\n\n\n\nContent\nVideo title\nVideo publish time\nComments added\nAverage percentage viewed (%)\nLikes\nViews\nImpressions\nImpressions click-through rate (%)\n\n\n\n\n0\nWn9L1MD_y0Y\nHow To Send WhatsApp Messages From Excel Using...\n19-Dec-20\n885\n26.36\n3057\n265002\n2152704\n6.71\n\n\n1\nsvcv8uub0D0\nHow to Create an Excel Data Entry Form in 10 M...\n22-May-21\n207\n28.48\n3112\n99259\n1069755\n5.70\n\n\n2\nSb0A9i6d320\nTurn An Excel Sheet Into An Interactive Dashbo...\n11-Sep-21\n192\n13.14\n10175\n442044\n11550064\n2.79\n\n\n3\nVwzaNjpcEZ0\nSend BULK SMS From Your OWN Number Using EXCEL...\n10-Jul-21\n158\n27.57\n537\n50270\n341500\n9.04\n\n\n4\nnJHrSvYxzjE\nDeploy Your Streamlit Web App on Heroku For Fr...\n20-Mar-21\n114\n32.44\n966\n30941\n308074\n5.22\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n#printing the information\nraw.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 107 entries, 0 to 106\nData columns (total 9 columns):\n #   Column                              Non-Null Count  Dtype  \n---  ------                              --------------  -----  \n 0   Content                             107 non-null    object \n 1   Video title                         107 non-null    object \n 2   Video publish time                  102 non-null    object \n 3   Comments added                      107 non-null    int64  \n 4   Average percentage viewed (%)       107 non-null    float64\n 5   Likes                               107 non-null    int64  \n 6   Views                               107 non-null    int64  \n 7   Impressions                         107 non-null    int64  \n 8   Impressions click-through rate (%)  106 non-null    float64\ndtypes: float64(2), int64(4), object(3)\nmemory usage: 7.6+ KB\n\n\n\n#checking for missing values\nraw.isna().sum()\n\nContent                               0\nVideo title                           0\nVideo publish time                    5\nComments added                        0\nAverage percentage viewed (%)         0\nLikes                                 0\nViews                                 0\nImpressions                           0\nImpressions click-through rate (%)    1\ndtype: int64\n\n\n\n#gives the columns with missing values\nraw[raw.isnull().any(axis=\"columns\")]\n\n\n  \n    \n      \n\n\n\n\n\n\nContent\nVideo title\nVideo publish time\nComments added\nAverage percentage viewed (%)\nLikes\nViews\nImpressions\nImpressions click-through rate (%)\n\n\n\n\n94\n8E4se9Ah5o8\nMyToolBelt Installation\nNaN\n5\n72.18\n22\n1309\n13\n0.00\n\n\n96\nV3Csrk--laM\nCreate Invoice Filepath\nNaN\n5\n70.11\n1\n16\n5\n0.00\n\n\n100\nRnTqlKzQhRY\nPySimpleGUI Retrieve Data\nNaN\n4\n85.97\n6\n182\n78\n2.56\n\n\n105\nl4Dd1xLfNVY\nxlwings - demo\nNaN\n0\n102.23\n0\n3\n0\nNaN\n\n\n106\npqIjey6Cbhw\nHow to resolve \"pytube.exceptions.RegexMatchEr...\nNaN\n0\n44.91\n0\n13\n3\n0.00\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n#finding the top 3 rows with most values in a particular column\nraw.nlargest(3, columns=[\"Impressions\"])\n\n\n  \n    \n      \n\n\n\n\n\n\nContent\nVideo title\nVideo publish time\nComments added\nAverage percentage viewed (%)\nLikes\nViews\nImpressions\nImpressions click-through rate (%)\n\n\n\n\n2\nSb0A9i6d320\nTurn An Excel Sheet Into An Interactive Dashbo...\n11-Sep-21\n192\n13.14\n10175\n442044\n11550064\n2.79\n\n\n0\nWn9L1MD_y0Y\nHow To Send WhatsApp Messages From Excel Using...\n19-Dec-20\n885\n26.36\n3057\n265002\n2152704\n6.71\n\n\n1\nsvcv8uub0D0\nHow to Create an Excel Data Entry Form in 10 M...\n22-May-21\n207\n28.48\n3112\n99259\n1069755\n5.70\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n\nFinding correlation between columns and plotting it in more readable way\n\nraw.corr()\n\nFutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n  raw.corr()\n\n\n\n  \n    \n      \n\n\n\n\n\n\nComments added\nAverage percentage viewed (%)\nLikes\nViews\nImpressions\nImpressions click-through rate (%)\n\n\n\n\nComments added\n1.000000\n-0.141652\n0.484353\n0.672014\n0.362981\n0.224351\n\n\nAverage percentage viewed (%)\n-0.141652\n1.000000\n-0.202818\n-0.189377\n-0.163310\n-0.241190\n\n\nLikes\n0.484353\n-0.202818\n1.000000\n0.958418\n0.958740\n0.079380\n\n\nViews\n0.672014\n-0.189377\n0.958418\n1.000000\n0.923668\n0.134627\n\n\nImpressions\n0.362981\n-0.163310\n0.958740\n0.923668\n1.000000\n-0.015123\n\n\nImpressions click-through rate (%)\n0.224351\n-0.241190\n0.079380\n0.134627\n-0.015123\n1.000000\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nraw.corr().style.background_gradient(cmap='RdBu',vmin=-1,vmax=1)\n\nFutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n  raw.corr().style.background_gradient(cmap='RdBu',vmin=-1,vmax=1)\n\n\n\n\n\n\n\nÂ \nComments added\nAverage percentage viewed (%)\nLikes\nViews\nImpressions\nImpressions click-through rate (%)\n\n\n\n\nComments added\n1.000000\n-0.141652\n0.484353\n0.672014\n0.362981\n0.224351\n\n\nAverage percentage viewed (%)\n-0.141652\n1.000000\n-0.202818\n-0.189377\n-0.163310\n-0.241190\n\n\nLikes\n0.484353\n-0.202818\n1.000000\n0.958418\n0.958740\n0.079380\n\n\nViews\n0.672014\n-0.189377\n0.958418\n1.000000\n0.923668\n0.134627\n\n\nImpressions\n0.362981\n-0.163310\n0.958740\n0.923668\n1.000000\n-0.015123\n\n\nImpressions click-through rate (%)\n0.224351\n-0.241190\n0.079380\n0.134627\n-0.015123\n1.000000\n\n\n\n\n\n\nheatmap=sns.heatmap(raw.corr(),cmap=\"RdBu\",annot=True, fmt=\".3f\")\n\nFutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n  heatmap=sns.heatmap(raw.corr(),cmap=\"RdBu\",annot=True, fmt=\".3f\")\n\n\n\n\n\n\n\nPlotting pairwise distributions\n\nsns.pairplot(raw)\n\n\n\n\n\n# removing outliers for better visualization\nsns.pairplot(raw[raw[\"Views\"]&lt;raw[\"Views\"].quantile(0.99)])\n\n\n\n\n\n\nVisualizing time series data\n\n#converting the date column from object to datetime\nraw[\"Video publish time\"]=pd.to_datetime(raw[\"Video publish time\"])\nraw.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 107 entries, 0 to 106\nData columns (total 9 columns):\n #   Column                              Non-Null Count  Dtype         \n---  ------                              --------------  -----         \n 0   Content                             107 non-null    object        \n 1   Video title                         107 non-null    object        \n 2   Video publish time                  102 non-null    datetime64[ns]\n 3   Comments added                      107 non-null    int64         \n 4   Average percentage viewed (%)       107 non-null    float64       \n 5   Likes                               107 non-null    int64         \n 6   Views                               107 non-null    int64         \n 7   Impressions                         107 non-null    int64         \n 8   Impressions click-through rate (%)  106 non-null    float64       \ndtypes: datetime64[ns](1), float64(2), int64(4), object(2)\nmemory usage: 7.6+ KB\n\n\n\n# Sorting according to the date\nraw.sort_values(by=\"Video publish time\",inplace=True)\n\n\n#plot the likes with time\n(raw\n .set_index(\"Video publish time\")\n .sort_index()\n .Likes\n .resample(\"m\")\n .mean()\n .fillna(0)\n .plot(figsize=(16,3))\n)\n\n&lt;Axes: xlabel='Video publish time'&gt;\n\n\n\n\n\nWe can plot a more interactive time series plot using plotly\n\ndef plot_timeseries(df, columns):\n    df = df.set_index(\"Video publish time\").sort_index()\n    fig = px.line(\n        df,\n        x=df.index,\n        y=columns,\n        template=\"simple_white\",\n        hover_name=\"Video title\",\n        title=f\"Development: {', '.join(columns).title()}\",\n    )\n    fig.update_layout(hovermode=\"x unified\", margin=dict(l=0, r=0, t=50, b=5))\n    return fig\n\nfig = plot_timeseries(df=raw, columns=[\"Likes\",\"Comments added\"])\nfig.show()\n\n\n\n\n\n                                \n                                            \n\n\n\n\nI have used the following as reference for trying out these functionalities: https://www.youtube.com/watch?v=RXEP1R_ZNrs"
  },
  {
    "objectID": "blogs.html",
    "href": "blogs.html",
    "title": "Blog",
    "section": "",
    "text": "Pandas Cheat Sheet\n\n\n\n\n\n\n\nML\n\n\n\n\nSome introduction to Pandas functionality and plotting to understand data\n\n\n\n\n\n\nJun 2, 2023\n\n\nEshan Gujarathi\n\n\n\n\n\n\n  \n\n\n\n\nFCNN on MNIST\n\n\n\n\n\n\n\nML\n\n\n\n\nSimple FCNN on MNIST dataset and evaluation metrics\n\n\n\n\n\n\nMay 7, 2023\n\n\nEshan Gujarathi\n\n\n\n\n\n\nNo matching items"
  }
]